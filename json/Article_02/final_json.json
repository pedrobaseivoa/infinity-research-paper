{
  "vision_json": {
    "source": "gpt-4o-vision",
    "success": true,
    "prompt_sent": "Extract ONLY publication metadata from these academic paper pages.\n\nCRITICAL: This data will be sent to 11 external APIs, so format accuracy is essential.\n\nFIELD REQUIREMENTS WITH EXACT FORMATS:\n\n1. **Title**: Clean title for API queries (HIGHEST PRIORITY)\n   - Remove line breaks, extra spaces, formatting\n   - No HTML tags or special characters  \n   - Example: \"Effects of Machine Learning on Healthcare Outcomes\"\n\n2. **Authors**: API-compatible author list (HIGHEST PRIORITY)\n   - Each author as separate string in array\n   - Format: \"FirstName LastName\" or \"F. LastName\"\n   - Clean, no extra punctuation\n   - Example: [\"John Smith\", \"M. Johnson\", \"Sarah Williams\"]\n\n3. **DOI**: Standard DOI format for resolution APIs\n   - Must start with \"10.\" if present\n   - Clean format without URL prefixes\n   - Example: \"10.1234/journal.2024.001\"\n\n4. **Journal**: Clean journal name for database queries\n   - Full journal name preferred over abbreviations\n   - Remove extra formatting, parentheses\n   - Example: \"Nature Medicine\"\n\n5. **Year**: Numeric format for date filtering\n   - 4-digit NUMBER only (not string)\n   - Example: 2024\n\n6. **Volume**: Clean number for bibliographic APIs\n   - Numbers only, no \"Vol.\" prefix\n   - Example: \"15\"\n\n7. **Issue**: Clean number format\n   - Numbers only, no \"No.\" or \"Issue\" prefix\n   - Example: \"3\"\n\n8. **Pages**: Standard page range for citations\n   - Format: \"start-end\" or single page\n   - Example: \"123-135\" or \"45\"\n\n9. **PMID**: PubMed ID for medical APIs\n   - Numbers only, no \"PMID:\" prefix\n   - Example: \"12345678\"\n\n10. **PMCID**: PubMed Central ID for open access papers\n    - Numbers only, no \"PMC\" prefix\n    - Often appears near PMID in biomedical papers\n    - Example: \"9876543\"\n\n11. **Keywords**: API-compatible keyword list\n    - Each keyword as separate string\n    - Research-quality terms, no punctuation\n    - Example: [\"machine learning\", \"healthcare\", \"clinical outcomes\"]\n\n11. **Abstract**: Complete clean text (HIGHEST PRIORITY)\n    - Remove formatting, line breaks, extra spaces\n    - Complete sentences, proper punctuation\n    - Search thoroughly across ALL pages\n    - This is CRITICAL for Semantic Scholar and other APIs\n\n12. **Publisher**: Clean organization name\n    - Official publisher name\n    - Example: \"Elsevier\" or \"Nature Publishing Group\"\n\nABSTRACT EXTRACTION PRIORITY:\n- Look thoroughly across ALL pages for abstract sections\n- Extract COMPLETE text, including multiple paragraphs\n- Check: Abstract, Summary, Introduction summary paragraphs\n- This field is CRITICAL for API enrichment success\n\nReturn JSON format:\n{\n  \"Title\": \"clean title without formatting\",\n  \"Authors\": [\"Author One\", \"Author Two\"],\n  \"DOI\": \"10.xxxx/xxxxx\",\n  \"Journal\": \"clean journal name\", \n  \"Year\": 2024,\n  \"Volume\": \"15\",\n  \"Issue\": \"3\", \n  \"Pages\": \"123-135\",\n  \"Abstract\": \"complete clean abstract text\",\n  \"Keywords\": [\"keyword1\", \"keyword2\"],\n  \"PMID\": \"12345678\",\n  \"PMCID\": \"9876543\",\n  \"Publisher\": \"publisher name\"\n}\n\nReturn null for fields not clearly visible. The Abstract field is MOST IMPORTANT for downstream API success.",
    "cost_tracking": {
      "model": "gpt-4o",
      "call_type": "vision_extraction",
      "timestamp": "2025-07-22T14:53:12.242367",
      "input_cost": 0.007725,
      "total_cost": 0.012305,
      "output_cost": 0.00458,
      "input_tokens": 3090,
      "total_tokens": 3548,
      "output_tokens": 458
    },
    "input_details": {
      "dpi": 120,
      "max_tokens": 1500,
      "model_used": "gpt-4o",
      "temperature": 0.1,
      "page_strategy": "strategic",
      "image_resolution": "high",
      "processing_time_ms": 22181,
      "pdf_pages_processed": 3
    },
    "extracted_data": {
      "DOI": "10.1109/THMS.2024.3432735",
      "PMID": null,
      "Year": 2024,
      "Issue": "5",
      "PMCID": null,
      "Pages": "589-598",
      "Title": "ARMedicalSketch: Exploring 3D Sketching for Medical Image Using True 2D-3D Interlinked Visualization and Interaction",
      "Volume": "54",
      "Authors": [
        "Nan Zhang",
        "Tianqi Huang",
        "Hongen Liao"
      ],
      "Journal": "IEEE Transactions on Human-Machine Systems",
      "Abstract": "In traditional clinical practice, doctors often have to deal with 3D information based on 2D-displayed medical images. There is a considerable mismatch between the 2D and 3D dimensions in image interaction during clinical diagnosis, making image manipulation challenging and time-consuming. In this study, we explored 3D sketching for medical images using true 2D-3D interlinked visualization and interaction, presenting a novel AR environment named ARMedicalSketch. It supports image display enhancement preprocessing and 3D interaction tasks for original 3D medical images. Our interaction interface, based on 3D autostereoscopic display technology, provides both floating 3D display and 2D tablet display while enabling glasses-free visualization. We presented a method of 2D-3D interlinked visualization and interaction, employing synchronized projection visualization and a virtual synchronized interactive plane to establish an integrated relationship between 2D and 3D displays. Additionally, we utilized gesture sensors and a 2D touch tablet to capture the user's hand information for convenient interaction. We constructed the prototype system and evaluated it by studying 23 students and 2 clinical experts. The results showed improved user processing efficiency with medical images while maintaining 2D interaction accuracy, and the prototype displays strong 3D spatial accuracy. In the future, we aim to further enhance the interaction precision and application scenarios of ARMedicalSketch.",
      "Keywords": [
        "3D aerial display",
        "augmented reality",
        "autostereoscopic visualization",
        "human-computer interaction"
      ],
      "Publisher": "IEEE"
    },
    "pages_processed": 3,
    "extraction_matrix": {
      "_performance_summary": {
        "total_cost": 0.0,
        "data_source": "vision_json",
        "input_tokens": 0,
        "output_tokens": 0,
        "vision_status": "COMPLETE",
        "extraction_rate": 84.62,
        "extraction_source": "gpt-4o-vision",
        "performance_level": "EXCELLENT",
        "fields_with_content": 11,
        "processing_time_seconds": 0,
        "total_fields_in_response": 13
      }
    },
    "extraction_method": "vision_strategic_strategy",
    "extraction_quality": {
      "success_rate": 50.0,
      "quality_score": 50.0,
      "successful_fields": 11,
      "validation_details": {
        "errors": [],
        "is_valid": true,
        "warnings": [],
        "quality_score": 100,
        "completeness_score": 100.0
      },
      "total_fields_attempted": 13
    },
    "processing_time_ms": 22181,
    "raw_openai_response": {
      "content": "```json\n{\n  \"Title\": \"ARMedicalSketch: Exploring 3D Sketching for Medical Image Using True 2D-3D Interlinked Visualization and Interaction\",\n  \"Authors\": [\"Nan Zhang\", \"Tianqi Huang\", \"Hongen Liao\"],\n  \"DOI\": \"10.1109/THMS.2024.3432735\",\n  \"Journal\": \"IEEE Transactions on Human-Machine Systems\",\n  \"Year\": 2024,\n  \"Volume\": \"54\",\n  \"Issue\": \"5\",\n  \"Pages\": \"589-598\",\n  \"Abstract\": \"In traditional clinical practice, doctors often have to deal with 3D information based on 2D-displayed medical images. There is a considerable mismatch between the 2D and 3D dimensions in image interaction during clinical diagnosis, making image manipulation challenging and time-consuming. In this study, we explored 3D sketching for medical images using true 2D-3D interlinked visualization and interaction, presenting a novel AR environment named ARMedicalSketch. It supports image display enhancement preprocessing and 3D interaction tasks for original 3D medical images. Our interaction interface, based on 3D autostereoscopic display technology, provides both floating 3D display and 2D tablet display while enabling glasses-free visualization. We presented a method of 2D-3D interlinked visualization and interaction, employing synchronized projection visualization and a virtual synchronized interactive plane to establish an integrated relationship between 2D and 3D displays. Additionally, we utilized gesture sensors and a 2D touch tablet to capture the user's hand information for convenient interaction. We constructed the prototype system and evaluated it by studying 23 students and 2 clinical experts. The results showed improved user processing efficiency with medical images while maintaining 2D interaction accuracy, and the prototype displays strong 3D spatial accuracy. In the future, we aim to further enhance the interaction precision and application scenarios of ARMedicalSketch.\",\n  \"Keywords\": [\"3D aerial display\", \"augmented reality\", \"autostereoscopic visualization\", \"human-computer interaction\"],\n  \"PMID\": null,\n  \"PMCID\": null,\n  \"Publisher\": \"IEEE\"\n}\n```",
      "parsing_error": "Expecting value: line 1 column 1 (char 0)",
      "response_length": 2072,
      "parsing_successful": false
    },
    "processing_timestamp": "2025-07-22T14:53:12.242357"
  },
  "apis_raw_json": {
    "core": {
      "error": "No results found in CORE",
      "success": false,
      "timestamp": "2025-07-22T14:53:27.385288",
      "processing_time_ms": 14828
    },
    "doaj": {
      "error": "No DOI available for DOAJ search",
      "success": false,
      "timestamp": "2025-07-22T14:53:13.899403",
      "processing_time_ms": 1337
    },
    "arxiv": {
      "error": "No results found",
      "success": false,
      "timestamp": "2025-07-22T14:53:14.083990",
      "processing_time_ms": 1526
    },
    "orcid": {
      "data": {
        "person": {
          "name": {
            "path": "0000-0001-9475-4994",
            "source": null,
            "visibility": "public",
            "credit-name": null,
            "family-name": {
              "value": "Zhang"
            },
            "given-names": {
              "value": "Nan-nan"
            },
            "created-date": {
              "value": 1541335278915
            },
            "last-modified-date": {
              "value": 1541335279142
            }
          },
          "path": "/0000-0001-9475-4994/person",
          "emails": {
            "path": "/0000-0001-9475-4994/email",
            "email": [],
            "last-modified-date": null
          },
          "keywords": {
            "path": "/0000-0001-9475-4994/keywords",
            "keyword": [],
            "last-modified-date": null
          },
          "addresses": {
            "path": "/0000-0001-9475-4994/address",
            "address": [],
            "last-modified-date": null
          },
          "biography": null,
          "other-names": {
            "path": "/0000-0001-9475-4994/other-names",
            "other-name": [],
            "last-modified-date": null
          },
          "researcher-urls": {
            "path": "/0000-0001-9475-4994/researcher-urls",
            "researcher-url": [],
            "last-modified-date": null
          },
          "last-modified-date": null,
          "external-identifiers": {
            "path": "/0000-0001-9475-4994/external-identifiers",
            "last-modified-date": null,
            "external-identifier": []
          }
        },
        "orcid_id": "0000-0001-9475-4994"
      },
      "success": true,
      "timestamp": "2025-07-22T14:53:13.996646",
      "processing_time_ms": 1434
    },
    "pubmed": {
      "error": "No results found",
      "success": false,
      "timestamp": "2025-07-22T14:53:18.777243",
      "processing_time_ms": 6229
    },
    "crossref": {
      "data": {
        "status": "ok",
        "message": {
          "DOI": "10.1109/thms.2024.3432735",
          "URL": "https://doi.org/10.1109/thms.2024.3432735",
          "ISSN": [
            "2168-2291",
            "2168-2305"
          ],
          "link": [
            {
              "URL": "http://xplorestaging.ieee.org/ielx8/6221037/10684406/10622100.pdf?arnumber=10622100",
              "content-type": "unspecified",
              "content-version": "vor",
              "intended-application": "similarity-checking"
            }
          ],
          "page": "589-598",
          "type": "journal-article",
          "issue": "5",
          "score": 1,
          "title": [
            "ARMedicalSketch: Exploring 3D Sketching for Medical Image Using True 2D-3D Interlinked Visualization and Interaction"
          ],
          "author": [
            {
              "ORCID": "https://orcid.org/0000-0002-3476-2201",
              "given": "Nan",
              "family": "Zhang",
              "sequence": "first",
              "affiliation": [
                {
                  "name": "Department of Biomedical Engineering, School of Medicine, Tsinghua University, Beijing, China"
                }
              ],
              "authenticated-orcid": false
            },
            {
              "ORCID": "https://orcid.org/0000-0002-9242-2408",
              "given": "Tianqi",
              "family": "Huang",
              "sequence": "additional",
              "affiliation": [
                {
                  "name": "School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China"
                }
              ],
              "authenticated-orcid": false
            },
            {
              "ORCID": "https://orcid.org/0000-0003-3847-9347",
              "given": "Hongen",
              "family": "Liao",
              "sequence": "additional",
              "affiliation": [
                {
                  "name": "Department of Biomedical Engineering, School of Medicine, Tsinghua University, Beijing, China"
                }
              ],
              "authenticated-orcid": false
            }
          ],
          "funder": [
            {
              "id": [
                {
                  "id": "10.13039/501100001809",
                  "id-type": "DOI",
                  "asserted-by": "publisher"
                }
              ],
              "DOI": "10.13039/501100001809",
              "name": "National Natural Science Foundation of China",
              "award": [
                "U22A2051",
                "82027807",
                "62101305"
              ],
              "doi-asserted-by": "publisher"
            },
            {
              "name": "National Key Research and Development Program of China",
              "award": [
                "2022YFC2405200"
              ]
            },
            {
              "name": "Intelligent Healthcare Tsinghua University",
              "award": [
                "2022ZLB001"
              ]
            },
            {
              "name": "Tsinghua-Foshan Innovation Special Fund",
              "award": [
                "2021THFS0104"
              ]
            }
          ],
          "issued": {
            "date-parts": [
              [
                2024,
                10
              ]
            ]
          },
          "member": "263",
          "prefix": "10.1109",
          "source": "Crossref",
          "volume": "54",
          "created": {
            "date-time": "2024-08-02T17:27:22Z",
            "timestamp": 1722619642000,
            "date-parts": [
              [
                2024,
                8,
                2
              ]
            ]
          },
          "indexed": {
            "version": "3.37.3",
            "date-time": "2025-07-05T04:48:26Z",
            "timestamp": 1751690906472,
            "date-parts": [
              [
                2025,
                7,
                5
              ]
            ]
          },
          "license": [
            {
              "URL": "https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html",
              "start": {
                "date-time": "2024-10-01T00:00:00Z",
                "timestamp": 1727740800000,
                "date-parts": [
                  [
                    2024,
                    10,
                    1
                  ]
                ]
              },
              "delay-in-days": 0,
              "content-version": "vor"
            },
            {
              "URL": "https://doi.org/10.15223/policy-029",
              "start": {
                "date-time": "2024-10-01T00:00:00Z",
                "timestamp": 1727740800000,
                "date-parts": [
                  [
                    2024,
                    10,
                    1
                  ]
                ]
              },
              "delay-in-days": 0,
              "content-version": "stm-asf"
            },
            {
              "URL": "https://doi.org/10.15223/policy-037",
              "start": {
                "date-time": "2024-10-01T00:00:00Z",
                "timestamp": 1727740800000,
                "date-parts": [
                  [
                    2024,
                    10,
                    1
                  ]
                ]
              },
              "delay-in-days": 0,
              "content-version": "stm-asf"
            }
          ],
          "subject": [],
          "relation": {},
          "resource": {
            "primary": {
              "URL": "https://ieeexplore.ieee.org/document/10622100/"
            }
          },
          "subtitle": [],
          "deposited": {
            "date-time": "2024-11-05T18:34:39Z",
            "timestamp": 1730831679000,
            "date-parts": [
              [
                2024,
                11,
                5
              ]
            ]
          },
          "issn-type": [
            {
              "type": "print",
              "value": "2168-2291"
            },
            {
              "type": "electronic",
              "value": "2168-2305"
            }
          ],
          "published": {
            "date-parts": [
              [
                2024,
                10
              ]
            ]
          },
          "publisher": "Institute of Electrical and Electronics Engineers (IEEE)",
          "reference": [
            {
              "DOI": "10.1145/3290607.3312847",
              "key": "ref1",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1109/TLT.2022.3227100",
              "key": "ref2",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1145/210079.210087",
              "key": "ref3",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1145/3313831.3376628",
              "key": "ref4",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1001/archsurg.139.2.170",
              "key": "ref5",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1111/cgf.13710",
              "key": "ref6",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1145/3359996.3364254",
              "key": "ref7",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1201/9781420036879",
              "key": "ref8",
              "year": "2000",
              "author": "Spitzer",
              "volume-title": "Digital Avionics Handbook",
              "doi-asserted-by": "crossref"
            },
            {
              "key": "ref9",
              "year": "2016",
              "issue": "6",
              "author": "Gao",
              "volume": "28",
              "first-page": "896",
              "article-title": "A review on development of head mounted display",
              "journal-title": "J. Comput.-Aided Des. Comput. Graph."
            },
            {
              "DOI": "10.1109/JPROC.2017.2648796",
              "key": "ref10",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1002/sdtp.14444",
              "key": "ref11",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1109/TBME.2010.2040278",
              "key": "ref12",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1364/JOSAA.452915",
              "key": "ref13",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1145/3072959.3073624",
              "key": "ref14",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1364/OE.23.006533",
              "key": "ref15",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1364/AO.33.007453",
              "key": "ref16",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1109/2.910892",
              "key": "ref17",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1109/TVCG.2007.1060",
              "key": "ref18",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1145/1449715.1449740",
              "key": "ref19",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1145/1185657.1185770",
              "key": "ref20",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1145/364338.364370",
              "key": "ref21",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1145/3173574.3173759",
              "key": "ref22",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1145/3411764.3445302",
              "key": "ref23",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1145/985692.985767",
              "key": "ref24",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1145/3411764.3445158",
              "key": "ref25",
              "doi-asserted-by": "publisher"
            },
            {
              "key": "ref26",
              "author": "Saalfeld",
              "first-page": "123",
              "volume-title": "Proc. VCBMMedViz",
              "article-title": "Semi-immersive 3D sketching of vascular structures for medical education"
            },
            {
              "key": "ref27",
              "author": "Saalfeld",
              "first-page": "5",
              "volume-title": "Proc. Eurographics (Dirk Bartz Prize)",
              "article-title": "Sketching and annotating vascular structures to support medical teaching, treatment planning and patient education"
            },
            {
              "DOI": "10.1111/cgf.12193",
              "key": "ref28",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1111/j.1467-8659.2010.01803.x",
              "key": "ref29",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1145/3009939.3009956",
              "key": "ref30",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.5948/upo9781614440260.011",
              "key": "ref31",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1016/S0166-4115(08)62386-9",
              "key": "ref32",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1007/s11605-019-04214-z",
              "key": "ref33",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.3390/app11167323",
              "key": "ref34",
              "doi-asserted-by": "publisher"
            },
            {
              "DOI": "10.1007/s00464-009-0740-8",
              "key": "ref35",
              "doi-asserted-by": "publisher"
            }
          ],
          "short-title": [],
          "journal-issue": {
            "issue": "5"
          },
          "content-domain": {
            "domain": [],
            "crossmark-restriction": false
          },
          "original-title": [],
          "container-title": [
            "IEEE Transactions on Human-Machine Systems"
          ],
          "published-print": {
            "date-parts": [
              [
                2024,
                10
              ]
            ]
          },
          "reference-count": 35,
          "references-count": 35,
          "short-container-title": [
            "IEEE Trans. Human-Mach. Syst."
          ],
          "is-referenced-by-count": 1
        },
        "message-type": "work",
        "message-version": "1.0.0"
      },
      "success": true,
      "timestamp": "2025-07-22T14:53:13.878834",
      "processing_time_ms": 1332
    },
    "datacite": {
      "error": "No matching articles found",
      "success": false,
      "timestamp": "2025-07-22T14:53:21.076509",
      "processing_time_ms": 8518
    },
    "openalex": {
      "data": {
        "id": "https://openalex.org/W4401247280",
        "doi": "https://doi.org/10.1109/thms.2024.3432735",
        "title": "ARMedicalSketch: Exploring 3D Sketching for Medical Image Using True 2D-3D Interlinked Visualization and Interaction",
        "open_access": {
          "is_oa": false,
          "oa_url": null,
          "oa_status": "closed",
          "any_repository_has_fulltext": false
        },
        "cited_by_count": 0,
        "publication_year": 2024
      },
      "success": true,
      "timestamp": "2025-07-22T14:53:13.752971",
      "processing_time_ms": 1202
    },
    "unpaywall": {
      "data": {
        "doi": "10.1109/thms.2024.3432735",
        "year": 2024,
        "genre": "journal-article",
        "is_oa": false,
        "title": "ARMedicalSketch: Exploring 3D Sketching for Medical Image Using True 2D-3D Interlinked Visualization and Interaction",
        "doi_url": "https://doi.org/10.1109/thms.2024.3432735",
        "oa_status": "closed",
        "publisher": "Institute of Electrical and Electronics Engineers (IEEE)",
        "is_paratext": false,
        "journal_name": "IEEE Transactions on Human-Machine Systems",
        "journal_issns": "2168-2291,2168-2305",
        "journal_issn_l": "2168-2291",
        "published_date": "2024-08-02",
        "z_authors_summary": {
          "count": 3,
          "first_author": ""
        },
        "has_repository_copy": false,
        "oa_locations_summary": {
          "count": 0,
          "has_repository": false
        },
        "best_oa_location_summary": null,
        "first_oa_location_summary": null
      },
      "success": true,
      "timestamp": "2025-07-22T14:53:14.020442",
      "processing_time_ms": 1465
    },
    "europe_pmc": {
      "error": "No results found",
      "success": false,
      "timestamp": "2025-07-22T14:53:14.286742",
      "processing_time_ms": 1734
    },
    "semantic_scholar": {
      "data": {
        "year": 2024,
        "title": "ARMedicalSketch: Exploring 3D Sketching for Medical Image Using True 2D-3D Interlinked Visualization and Interaction",
        "authors": [
          {
            "name": "Nan Zhang",
            "authorId": "2153284083"
          },
          {
            "name": "Tianqi Huang",
            "authorId": "144200237"
          },
          {
            "name": "Hongen Liao",
            "authorId": "2254309703"
          }
        ],
        "journal": {
          "name": "IEEE Transactions on Human-Machine Systems",
          "pages": "589-598",
          "volume": "54"
        },
        "paperId": "05c87560ba379b350fa9de8ab4392275c0dfab23",
        "abstract": "In traditional clinical practice, doctors often have to deal with 3D information based on 2D-displayed medical images. There is a considerable mismatch between the 2D and 3D dimensions in image interaction during clinical diagnosis, making image manipulation challenging and time-consuming. In this study, we explored 3D sketching for medical images using true 2D-3D interlinked visualization and interaction, presenting a novel AR environment named ARMedicalSketch. It supports image display enhancement preprocessing and 3D interaction tasks for original 3D medical images. Our interaction interface, based on 3D autostereoscopic display technology, provides both floating 3D display and 2D tablet display while enabling glasses-free visualization. We presented a method of 2D-3D interlinked visualization and interaction, employing synchronized projection visualization and a virtual synchronized interactive plane to establish an integrated relationship between 2D and 3D displays. Additionally, we utilized gesture sensors and a 2D touch tablet to capture the user's hand information for convenient interaction. We constructed the prototype and conducted a user study involving 23 students and 2 clinical experts. The controlled study compared our proposed system with a 2D display prototype, showing enhanced efficiency in interacting with medical images while maintaining 2D interaction accuracy, particularly in tasks involving strong 3D spatial correlation. In the future, we aim to further enhance the interaction precision and application scenarios of ARMedicalSketch.",
        "externalIds": {
          "DOI": "10.1109/THMS.2024.3432735",
          "DBLP": "journals/thms/ZhangHL24",
          "CorpusId": 271681932
        },
        "isOpenAccess": false,
        "citationCount": 0,
        "openAccessPdf": {
          "url": "",
          "status": null,
          "license": null,
          "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/THMS.2024.3432735?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/THMS.2024.3432735, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
        }
      },
      "success": true,
      "timestamp": "2025-07-22T14:53:13.671126",
      "processing_time_ms": 1122
    }
  },
  "questions_json": {
    "reason": "custom_topics_not_enabled",
    "success": false,
    "extraction_method": "disabled",
    "processing_timestamp": "2025-07-22T14:55:11.256820"
  },
  "apis_clean_json": {
    "timestamp": "2025-07-22T14:54:20.911135",
    "cost_tracking": {
      "model": "deepseek-chat",
      "call_type": "smart_consensus",
      "timestamp": "2025-07-22T14:54:20.910920",
      "input_cost": 0.001852,
      "total_cost": 0.002998,
      "output_cost": 0.001146,
      "input_tokens": 6859,
      "total_tokens": 7901,
      "output_tokens": 1042,
      "parsing_error": null,
      "parsing_successful": true,
      "processing_time_ms": 53491
    },
    "consensus_result": {
      "DOI": "10.1109/THMS.2024.3432735",
      "PMID": null,
      "Year": 2024,
      "Issue": "5",
      "PMCID": null,
      "Pages": "589-598",
      "Title": "ARMedicalSketch: Exploring 3D Sketching for Medical Image Using True 2D-3D Interlinked Visualization and Interaction",
      "PDFUrl": null,
      "Volume": "54",
      "Authors": [
        "Zhang, Nan",
        "Huang, Tianqi",
        "Liao, Hongen"
      ],
      "Journal": "IEEE Transactions on Human-Machine Systems",
      "Abstract": "In traditional clinical practice, doctors often have to deal with 3D information based on 2D-displayed medical images. There is a considerable mismatch between the 2D and 3D dimensions in image interaction during clinical diagnosis, making image manipulation challenging and time-consuming. In this study, we explored 3D sketching for medical images using true 2D-3D interlinked visualization and interaction, presenting a novel AR environment named ARMedicalSketch. It supports image display enhancement preprocessing and 3D interaction tasks for original 3D medical images. Our interaction interface, based on 3D autostereoscopic display technology, provides both floating 3D display and 2D tablet display while enabling glasses-free visualization. We presented a method of 2D-3D interlinked visualization and interaction, employing synchronized projection visualization and a virtual synchronized interactive plane to establish an integrated relationship between 2D and 3D displays. Additionally, we utilized gesture sensors and a 2D touch tablet to capture the user's hand information for convenient interaction. We constructed the prototype system and evaluated it by studying 23 students and 2 clinical experts. The results showed improved user processing efficiency with medical images while maintaining 2D interaction accuracy, and the prototype displays strong 3D spatial accuracy. In the future, we aim to further enhance the interaction precision and application scenarios of ARMedicalSketch.",
      "Keywords": [
        "3D aerial display",
        "augmented reality",
        "autostereoscopic visualization",
        "human-computer interaction"
      ],
      "Citations": 0,
      "Publisher": "IEEE",
      "OpenAccess": false,
      "confidence_factors": {
        "source": "Vision-Foundation + API Enhancement",
        "reasoning": "Vision data used as foundation with API validation confirming DOI, title, authors, and journal. API data enhanced citation count and open access status. All fields validated as coherent across multiple APIs.",
        "field_sources": {
          "doi": "crossref|openalex|semantic_scholar",
          "year": "vision",
          "issue": "vision",
          "pages": "vision",
          "title": "vision",
          "volume": "vision",
          "authors": "crossref+vision",
          "journal": "vision",
          "abstract": "vision",
          "keywords": "vision",
          "citations": "semantic_scholar",
          "publisher": "vision",
          "openaccess": "crossref|openalex|semantic_scholar|unpaywall"
        },
        "enhancement_level": "MODERATE",
        "validation_status": "HIGH"
      },
      "api_success_summary": {
        "insights": "Best contributors: Crossref, Semantic Scholar, OpenAlex. Failures due to no results in biomedical/engineering-focused APIs (PubMed, Europe PMC). High coherence among successful APIs confirms data quality.",
        "total_apis": 11,
        "failed_apis": [
          "doaj",
          "arxiv",
          "europe_pmc",
          "pubmed",
          "datacite",
          "core"
        ],
        "success_rate": 0.55,
        "coherent_apis": 5,
        "coherence_rate": 0.83,
        "successful_apis": 6
      }
    },
    "processing_time_ms": 68366
  },
  "llm_topics_json": {
    "success": true,
    "prompt_sent": "You are a scientific research assistant extracting data for academic comparison tables with statistical rigor.\n\nCRITICAL INSTRUCTIONS FOR ACADEMIC COMPARISON:\n\n- SYSTEMATICALLY scan ALL content: text, tables, figures, charts, appendices\n- PRIORITIZE quantitative data while preserving qualitative context\n- When conflicts exist in the paper, prioritize MOST RECENT/AUTHORITATIVE source\n- Extract ALL relevant details mentioned - DON'T truncate important information\n- Include statistical tests results (Z-scores, t-values, chi-square, etc.)\n- Extract accuracy rates, completion rates, success rates with specific numbers\n- Capture comparative data (e.g., \"46% vs 27%\", \"Group A: 64.5%, Group B: 68.2%\")\n- Use proper numeric format: \"p = 0.007\" not \"p = .007\", \"81\" not \"eighty-one\"\n\nCOMPREHENSIVE CAPTURE REQUIREMENTS:\n\n- List ALL hardware components: cameras, sensors, headsets, controllers, phones, tablets, webcams, probes\n- Include ALL software details: platforms, SDKs, libraries, export formats (CSV, JSON), feedback systems\n- Capture ALL measurement instruments: scales, questionnaires, assessment tools (SUS, NASA-TLX, FES-I, MoCA, IKDC, VAS, ABC scale, WHODAS 2.0, etc.)\n- Note ALL technical specifications: resolutions, frame rates, tracking capabilities, joint counts\n- Include ALL study phases: pilot tests, technical validation, user studies, expert evaluations\n- Capture ALL procedural details: training time, calibration steps, data export processes, real-time feedback\n\nCONFLICT RESOLUTION:\n\n- If conflicting information exists, prioritize methods/results over abstract\n- When uncertain, include both: \"X in abstract, Y in methods section\"\n\nExtract the following 7 scientific topics:\n\n1. *study_design*: Extract the PRIMARY study type/design using the most specific and authoritative terminology from the paper's methods section. Recognize equivalent terms: \"RCT\" = \"Randomized controlled trial\", \"Pilot study\" = \"Feasibility pilot study\", \"Cross-sectional\" = \"Observational cross-sectional\", \"User study\" = \"User evaluation study\". When multiple study type descriptions exist, prioritize the most comprehensive version from methods over abstract. Include specific qualifiers when mentioned (e.g., \"multicenter\", \"double-blind\", \"waitlist-controlled\") as these add valuable detail. Format as brief phrase describing core study methodology, avoiding generic terms like \"study\" or \"research\" alone.\n\n2. *methodology*: ONE comprehensive sentence covering: technology + application + key technical details. Include: ALL device models, software platforms, measurement tools, statistical analyses. Capture ALL hardware components mentioned (cameras, sensors, controllers, probes, etc.). Include ALL software features (real-time feedback, data export, tracking capabilities). Mention ALL technical specifications (joint tracking numbers, frame rates, resolutions). Example: \"Microsoft HoloLens 2 with HoloAnatomy platform for 3D anatomical procedural visualization using real-time motion tracking of 25 joints with CSV data export and real-time visual feedback\".\n\n3. *sample_size*: Format: \"X participants/patients\" (use paper's exact terminology). Include TOTAL numbers if multiple groups exist. Include ALL test phases: technical tests, pilot studies, user evaluations. Example: \"25 total: 23 biomedical students + 2 clinical experts; 50 technical validation readings\".\n\n4. *population*: ALL demographic details and characteristics not captured in sample_size. Include age, profession, condition, experience, setting details. Add specific numbers when available. Include recruitment sources and inclusion/exclusion criteria.\n\n5. *primary_outcome*: Include ALL measurement tools, scales, timing, specific metrics, usability criteria (ease of use, realism, anatomical accuracy). List ALL assessment instruments used and functional scales (SUS, NASA-TLX, FES-I, MoCA, IKDC, VAS, ABC scale, WHODAS 2.0, etc.), and evaluation dimensions beyond the primary measures.. Include ALL comparison conditions and timepoints. Example: \"Patient understanding via 5-point Likert scale assessed pre/post intervention, plus SUS usability scores and NASA-TLX workload assessment\".\n\n6. *key_findings*: PRIORITIZE statistical results with practical implications. Format: \"Finding 1: [statistical data + meaning]. Finding 2: [data + context]\". Include ALL significant findings, p-values, effect sizes, accuracy rates, comparative data, accuracy measurements (sub-mm, degrees), specific understanding domains (surgical risks, operative steps, recovery), and detailed performance metrics beyond statistical significance. Present ALL questionnaire results, prototype performance, qualitative benefits. Include ALL cost factors, training requirements, implementation details. Capture ALL comparison groups and their specific results. Be comprehensive - capture complete findings picture. Include ALL technical specifications mentioned: accuracy measurements (sub-mm, degrees).\n\n7. *limitations*: Extract ALL limitations from limitation/discussion sections. Include sample size issues, technical equipment requirements, methodological, practical constraints. Mention ALL equipment needs, calibration requirements, manufacturing variability. Include ALL generalizability issues, validity concerns, implementation barriers. Capture training requirements, cost constraints, specialized equipment needs. Note real-world applicability issues and clinical implementation challenges. Don't summarize - capture complete limitation landscape.\n\nReturn as valid JSON with this EXACT structure:\n\n{\n  \"study_design\": \"string\",\n  \"methodology\": \"string\",\n  \"sample_size\": \"string\",\n  \"population\": \"string\",\n  \"primary_outcome\": \"string\",\n  \"key_findings\": \"string\",\n  \"limitations\": \"string\"\n}",
    "cost_tracking": {
      "model": "gpt-4o",
      "call_type": "scientific_topics_multimodal",
      "timestamp": "2025-07-22T14:55:10.344262",
      "input_cost": 0.022045,
      "total_cost": 0.025325,
      "output_cost": 0.00328,
      "input_tokens": 8818,
      "total_tokens": 9146,
      "output_tokens": 328
    },
    "input_details": {
      "dpi": 150,
      "max_tokens": 6000,
      "model_used": "gpt-4o",
      "temperature": 0.1,
      "strategy_used": "vision_all_pages (≤40)",
      "pdf_total_pages": 10,
      "image_resolution": "high",
      "processing_time_ms": 48542,
      "pdf_pages_processed": 10
    },
    "pages_processed": 10,
    "extracted_topics": {
      "population": "Biomedical engineering students aged 21 to 33, including 13 males and 10 females, with no expertise in organ diagnosis of medical images.",
      "limitations": "Limitations include the need for further improvements in the accuracy of the prototype, coarse positioning information at the fingertip, and the requirement for specialized equipment like 3D autostereoscopic displays and gesture recognition devices.",
      "methodology": "The study utilized a novel AR environment named ARMedicalSketch with a 3D autostereoscopic display and 2D tablet for medical image sketching, employing gesture recognition and a virtual synchronized interactive plane, with technical specifications including a liquid crystal display panel resolution of 3840 x 2160 and 1920 x 1080, and a GeForce GTX 1660Ti GPU.",
      "sample_size": "23 volunteers",
      "key_findings": "Finding 1: Prototype 1 showed significant improvement in completion time for Task 2 (p < 0.01). Finding 2: SUS scores indicated high system usability (81.6/4 for Prototype 1, 76.8/2 for Prototype 2, p < 0.01). Finding 3: Interaction accuracy was consistent across prototypes, with Prototype 1 showing slightly more accurate spatial representation.",
      "study_design": "User evaluation study with control group",
      "primary_outcome": "System usability assessed via SUS, workload via NASA-TLX, and sketching efficiency and accuracy measured through completion time and positional deviation in 3D medical tasks."
    },
    "extraction_method": "multimodal_vision",
    "extraction_quality": {
      "topics_missing": 0,
      "topics_extracted": 7
    },
    "processing_time_ms": 48542,
    "raw_openai_response": {
      "content": "```json\n{\n  \"study_design\": \"User evaluation study with control group\",\n  \"methodology\": \"The study utilized a novel AR environment named ARMedicalSketch with a 3D autostereoscopic display and 2D tablet for medical image sketching, employing gesture recognition and a virtual synchronized interactive plane, with technical specifications including a liquid crystal display panel resolution of 3840 x 2160 and 1920 x 1080, and a GeForce GTX 1660Ti GPU.\",\n  \"sample_size\": \"23 volunteers\",\n  \"population\": \"Biomedical engineering students aged 21 to 33, including 13 males and 10 females, with no expertise in organ diagnosis of medical images.\",\n  \"primary_outcome\": \"System usability assessed via SUS, workload via NASA-TLX, and sketching efficiency and accuracy measured through completion time and positional deviation in 3D medical tasks.\",\n  \"key_findings\": \"Finding 1: Prototype 1 showed significant improvement in completion time for Task 2 (p < 0.01). Finding 2: SUS scores indicated high system usability (81.6/4 for Prototype 1, 76.8/2 for Prototype 2, p < 0.01). Finding 3: Interaction accuracy was consistent across prototypes, with Prototype 1 showing slightly more accurate spatial representation.\",\n  \"limitations\": \"Limitations include the need for further improvements in the accuracy of the prototype, coarse positioning information at the fingertip, and the requirement for specialized equipment like 3D autostereoscopic displays and gesture recognition devices.\"\n}\n```",
      "parsing_error": null,
      "response_length": 1487,
      "parsing_successful": true
    },
    "processing_timestamp": "2025-07-22T14:55:10.344132"
  },
  "processing_metadata": {
    "filename": "ARMedicalSketch_Exploring_3D_Sketching_for_Medical_Image_Using_True_2D-3D_Interlinked_Visualization_and_Interaction-2.pdf",
    "article_id": "unknown",
    "total_phases": 5,
    "aggregated_at": "2025-07-22T14:55:11.494731",
    "phases_completed": {
      "topics": true,
      "vision": true,
      "apis_raw": true,
      "questions": false,
      "apis_clean": true
    },
    "transparency_level": "complete"
  }
}